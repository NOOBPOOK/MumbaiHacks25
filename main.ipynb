{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cb444cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from crewai import Agent, Task, Crew\n",
    "from crewai.process import Process\n",
    "\n",
    "\n",
    "# 1. Initialize the Language Model (LLM)\n",
    "# It is assumed that the OPENAI_API_KEY environment variable is set.\n",
    "# ChatOpenAI uses the environment variable automatically.\n",
    "# You can replace this with any other supported LLM by CrewAI/LangChain,\n",
    "# such as Groq, Mistral, Ollama, etc.\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# 2. Define the Agent(s)\n",
    "\n",
    "researcher = Agent(\n",
    "    role='Senior Research Analyst',\n",
    "    goal='Discover and summarize the latest trends in renewable energy',\n",
    "    backstory='An expert in sustainability and market analysis. Meticulous and detail-oriented.',\n",
    "    verbose=True,\n",
    "    allow_delegation=False,\n",
    "    llm=llm  # Inject the initialized LLM here\n",
    ")\n",
    "\n",
    "# 3. Define the Task(s)\n",
    "\n",
    "research_task = Task(\n",
    "    description=(\n",
    "        \"Analyze the current global news and market data for renewable energy. \"\n",
    "        \"Specifically focus on **solar panel efficiency** improvements and **battery storage** \"\n",
    "        \"innovations over the last six months. \"\n",
    "        \"The final output must be a concise, three-paragraph summary.\"\n",
    "    ),\n",
    "    expected_output='A three-paragraph summary report on solar and battery advancements.',\n",
    "    agent=researcher  # Assign the task to the defined agent\n",
    ")\n",
    "\n",
    "# 4. Create the Crew and Run the Process\n",
    "\n",
    "# For simplicity, this example uses a single agent and a single task.\n",
    "# A full crew typically has multiple agents and multiple tasks.\n",
    "project_crew = Crew(\n",
    "    agents=[researcher],\n",
    "    tasks=[research_task],\n",
    "    process=Process.sequential,  # Execute tasks in order\n",
    "    verbose=2  # High verbosity for observing the agent's thought process\n",
    ")\n",
    "\n",
    "print(\"### Crew Starting Execution ###\")\n",
    "\n",
    "# Prompting the LLM is implicitly handled when the crew is kicked off,\n",
    "# as the agents use the LLM to process their assigned tasks and goals.\n",
    "result = project_crew.kickoff()\n",
    "\n",
    "# 5. Output the Result\n",
    "\n",
    "print(\"\\n\\n### Task Execution Complete ###\")\n",
    "print(f\"Final Report:\\n{result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447b7411",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Extract the claims and return a JSON for each claim retrieved from the argument.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f4c430",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from crewai import Agent, Task, Crew, LLM\n",
    "from crewai.process import Process\n",
    "\n",
    "# Ensure the environment variable is set before running:\n",
    "# export GEMINI_API_KEY=\"YOUR_API_KEY\"\n",
    "\n",
    "# 1. Initialize the LLM for Gemini\n",
    "# CrewAI uses a simplified LLM class that interfaces with LiteLLM.\n",
    "# The model name must be provided in the format: <provider>/<model_name>\n",
    "# Common Gemini models: gemini/gemini-2.5-flash, gemini/gemini-2.5-pro\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "gemini_llm = LLM(\n",
    "    model='gemini/gemini-2.5-pro',\n",
    "    # LiteLLM automatically uses GEMINI_API_KEY from environment\n",
    "    temperature=0.1\n",
    ")\n",
    "\n",
    "# 2. Define the Agent, injecting the Gemini LLM\n",
    "gemini_researcher = Agent(\n",
    "    role='AI Configuration Specialist',\n",
    "    goal='Provide a concise, detailed report on Gemini LLM integration into CrewAI.',\n",
    "    backstory='An expert in multi-agent orchestration frameworks and Google AI APIs. Highly accurate and focused on syntax.',\n",
    "    verbose=True,\n",
    "    allow_delegation=False,\n",
    "    llm=gemini_llm # <-- Inject the configured Gemini LLM here\n",
    ")\n",
    "\n",
    "# 3. Define the Task\n",
    "integration_task = Task(\n",
    "    description=(\n",
    "        \"Summarize the Python steps required to initialize a CrewAI Agent using the 'gemini/gemini-2.5-flash' model. \"\n",
    "        \"The summary must explicitly mention the required environment variable for the API key.\"\n",
    "    ),\n",
    "    expected_output='A four-step guide covering installation, API key variable, LLM initialization syntax, and Agent injection.',\n",
    "    agent=gemini_researcher\n",
    ")\n",
    "\n",
    "# 4. Create and Run the Crew\n",
    "project_crew = Crew(\n",
    "    agents=[gemini_researcher],\n",
    "    tasks=[integration_task],\n",
    "    process=Process.sequential,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"### Crew Starting Execution with Gemini ###\")\n",
    "\n",
    "result = project_crew.kickoff()\n",
    "\n",
    "print(\"\\n\\n### Gemini Crew Task Complete ###\")\n",
    "print(f\"Final Report:\\n{result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e781c8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from crewai import Agent, Task, Crew, LLM\n",
    "from crewai.process import Process\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "# --- 1. CONFIGURATION AND SCHEMA ---\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Define the structured output schema using Pydantic\n",
    "class Claim(BaseModel):\n",
    "    \"\"\"Represents a single verifiable claim extracted from the text.\"\"\"\n",
    "    claim_id: int = Field(description=\"A unique integer ID for this claim, starting from 1.\")\n",
    "    statement: str = Field(description=\"The exact claim or assertion made in the text.\")\n",
    "    confidence_score: float = Field(description=\"A score from 0.0 to 1.0 indicating the certainty of the claim's existence in the text.\")\n",
    "    verifiable: bool = Field(description=\"True if the claim contains factual, potentially provable information; False if it is an opinion, definition, or prediction.\")\n",
    "\n",
    "class ClaimList(BaseModel):\n",
    "    \"\"\"The final list structure for all claims extracted.\"\"\"\n",
    "    claims: List[Claim] = Field(description=\"A list containing all claims extracted from the input text.\")\n",
    "\n",
    "\n",
    "# --- 2. LLM SETUP ---\n",
    "\n",
    "# Initialize the Gemini LLM\n",
    "# LiteLLM automatically uses the GEMINI_API_KEY environment variable.\n",
    "gemini_llm = LLM(\n",
    "    model='gemini/gemini-2.5-flash',\n",
    "    temperature=0.0, # Low temperature for reliable extraction and JSON generation\n",
    "    # Setting max_retries ensures robustness in structured output generation\n",
    "    max_retries=3 \n",
    ")\n",
    "\n",
    "# --- 3. AGENT DEFINITION ---\n",
    "\n",
    "claim_extractor_agent = Agent(\n",
    "    role='Structured Claim Extractor',\n",
    "    goal='Accurately identify all verifiable claims within a given text and structure them according to the required JSON schema.',\n",
    "    backstory='You are a meticulous language model specializing in parsing unstructured text into clean, valid JSON format. You are highly reliable in detecting subtle assertions and assigning accurate confidence scores.',\n",
    "    verbose=True,\n",
    "    allow_delegation=False,\n",
    "    llm=gemini_llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c70912",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. TASK DEFINITION ---\n",
    "\n",
    "INPUT_TEXT = \"\"\"\n",
    "ðŸ”¥ BREAKING â€“ UNBELIEVABLE!!! ðŸ”¥\n",
    "Just came across this mind-blowing photo â€” all the biggest tech bosses hanging out together over Thanksgiving dinner! ðŸ˜²ðŸ¦ƒ\n",
    "\n",
    "Thereâ€™s Elon Musk, Mark Zuckerberg, Sundar Pichai, Satya Nadella, Tim Cook â€” sitting around a table like old friends, laughing, talking, drinks on the table. ðŸ·ðŸ½ï¸\n",
    "Someone is saying this was snapped right after a secret â€œsuper-AI summitâ€ where they met to decide the future of AI & Web. ðŸ’¡ðŸ¤–\n",
    "\n",
    "Itâ€™s â€œthe most powerful dinnerâ€ ever â€” feels crazy that these guys, who usually fight behind closed doors, are chilling together! ðŸ˜®\n",
    "\n",
    "If this image is real, it means something big is cooking ðŸ‘€â€¦ share this around so everyone sees! ðŸŒðŸ”¥\n",
    "\"\"\"\n",
    "\n",
    "extraction_task = Task(\n",
    "    description=(\n",
    "        f\"Analyze the following text and extract all distinct, factual claims. \"\n",
    "        f\"Ignore opinions, definitions, or predictions unless they contain a concrete, measurable assertion.\\n\\n\"\n",
    "        f\"TEXT TO ANALYZE:\\n---\\n{INPUT_TEXT}\\n---\"\n",
    "    ),\n",
    "    expected_output=\"A list of claims strictly formatted as a JSON array conforming to the Pydantic ClaimList schema.\",\n",
    "    agent=claim_extractor_agent,\n",
    "    # Crucial step: enforce structured output using the Pydantic model\n",
    "    output_pydantic=ClaimList\n",
    ")\n",
    "\n",
    "# --- 5. CREW EXECUTION ---\n",
    "\n",
    "claim_crew = Crew(\n",
    "    agents=[claim_extractor_agent],\n",
    "    tasks=[extraction_task],\n",
    "    process=Process.sequential,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Execute the crew\n",
    "print(\"--- Starting Claim Extraction ---\")\n",
    "crew_result = claim_crew.kickoff()\n",
    "\n",
    "# --- 6. OUTPUT PROCESSING ---\n",
    "\n",
    "# Access the structured Pydantic output directly\n",
    "if crew_result.tasks_output and hasattr(crew_result.tasks_output[0], 'pydantic'):\n",
    "    final_claim_list: ClaimList = crew_result.tasks_output[0].pydantic\n",
    "    \n",
    "    print(\"\\n--- Final Structured JSON Output ---\")\n",
    "    # Convert the Pydantic model to a pretty JSON string\n",
    "    print(json.dumps(final_claim_list.model_dump(), indent=4))\n",
    "    \n",
    "    print(\"\\n--- Programmatic Access Example ---\")\n",
    "    for claim in final_claim_list.claims:\n",
    "        print(f\"ID: {claim.claim_id} | Verifiable: {claim.verifiable} | Statement: {claim.statement}\")\n",
    "else:\n",
    "    print(\"\\n--- Error: Failed to retrieve structured Pydantic output. ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f1d6a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
